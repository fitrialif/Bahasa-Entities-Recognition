{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12194"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('entities-bm.txt','r') as fopen:\n",
    "    texts= list(filter(None, fopen.read().split('\\n')))\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag2idx = {'PAD': 0}\n",
    "char2idx = {'PAD': 0}\n",
    "tag_idx = 1\n",
    "char_idx = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_word(word, lower=True):\n",
    "    if lower:\n",
    "        word = word.lower()\n",
    "    else:\n",
    "        if word.isupper():\n",
    "            word = word.title()\n",
    "    word = re.sub('[^A-Za-z0-9\\- ]+', '', word)\n",
    "    if word.isdigit():\n",
    "        word = 'NUM'\n",
    "    return word\n",
    "\n",
    "def read_file(f):\n",
    "    global tag_idx, char_idx\n",
    "    words, tags, X, Y = [], [], [], []\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if (len(line) == 0 or line.startswith(\"-DOCSTART-\")):\n",
    "            continue\n",
    "        else:\n",
    "            ls = line.split(' ')\n",
    "            if len(ls) > 1:\n",
    "                word, tag = ls[0],ls[-1]\n",
    "            else:\n",
    "                word = ls[0]\n",
    "                tag = 'O'\n",
    "            word = process_word(word)\n",
    "            if len(word) < 1:\n",
    "                continue\n",
    "            char_ids = []\n",
    "            for c in word:\n",
    "                if c not in char2idx:\n",
    "                    char2idx[c] = char_idx\n",
    "                    char_idx += 1\n",
    "                char_ids.append(char2idx[c])\n",
    "            words += [word]\n",
    "            tags += [tag]\n",
    "            X.append(char_ids)\n",
    "            if tag not in tag2idx:\n",
    "                tag2idx[tag] = tag_idx\n",
    "                tag_idx += 1\n",
    "            Y.append(tag2idx[tag])\n",
    "                        \n",
    "    return words, tags, X, np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "words, _, _, Y = read_file(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = CountVectorizer(ngram_range=(1, 1), analyzer='char').fit(words)\n",
    "tfidf = TfidfVectorizer(ngram_range=(1, 1), analyzer='char').fit(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.hstack([bow.transform(words).todense(),tfidf.transform(words).todense()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy validation set:  0.7554972103708566\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       NORP       0.00      0.00      0.00       405\n",
      "        FAC       0.79      0.95      0.86      9275\n",
      "        ART       0.52      0.18      0.26      1190\n",
      "        ORG       0.10      0.10      0.10       130\n",
      "       TIME       0.33      0.34      0.33       304\n",
      "        PAD       0.25      0.08      0.13       106\n",
      "        LAW       0.33      0.09      0.15       106\n",
      "        PRN       0.31      0.04      0.07       514\n",
      "        DOC       0.33      0.05      0.08        64\n",
      "        LOC       0.00      0.00      0.00        93\n",
      "      EVENT       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.68      0.76      0.70     12188\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1428: UserWarning: labels size, 11, does not match size of target_names, 12\n",
      "  .format(len(labels), len(target_names))\n"
     ]
    }
   ],
   "source": [
    "bayes = MultinomialNB().fit(X, Y)\n",
    "predicted = bayes.predict(X)\n",
    "print('accuracy validation set: ', np.mean(predicted == Y))\n",
    "\n",
    "# print scores\n",
    "print(classification_report(Y, predicted, target_names=tag2idx.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12188, 12025)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "for i in range(1,5):\n",
    "    results.append(CountVectorizer(ngram_range=(1, i), analyzer='char').fit_transform(words).todense())\n",
    "    \n",
    "X = np.hstack(results)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy validation set:  0.8108795536593371\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       NORP       0.49      0.54      0.51       405\n",
      "        FAC       0.91      0.89      0.90      9275\n",
      "        ART       0.59      0.66      0.63      1190\n",
      "        ORG       0.71      0.44      0.54       130\n",
      "       TIME       0.44      0.57      0.50       304\n",
      "        PAD       0.52      0.28      0.37       106\n",
      "        LAW       0.61      0.18      0.28       106\n",
      "        PRN       0.43      0.57      0.49       514\n",
      "        DOC       0.69      0.17      0.28        64\n",
      "        LOC       0.76      0.30      0.43        93\n",
      "      EVENT       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.82      0.81      0.81     12188\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1428: UserWarning: labels size, 11, does not match size of target_names, 12\n",
      "  .format(len(labels), len(target_names))\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "bayes = MultinomialNB().fit(X, Y)\n",
    "predicted = bayes.predict(X)\n",
    "print('accuracy validation set: ', np.mean(predicted == Y))\n",
    "\n",
    "# print scores\n",
    "print(classification_report(Y, predicted, target_names=tag2idx.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12188, 12025)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "for i in range(1,5):\n",
    "    results.append(TfidfVectorizer(ngram_range=(1, i), analyzer='char').fit_transform(words).todense())\n",
    "    \n",
    "X = np.hstack(results)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy validation set:  0.8188382015096817\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       NORP       0.68      0.29      0.41       405\n",
      "        FAC       0.85      0.97      0.91      9275\n",
      "        ART       0.64      0.52      0.57      1190\n",
      "        ORG       0.95      0.15      0.25       130\n",
      "       TIME       0.42      0.32      0.36       304\n",
      "        PAD       0.38      0.11      0.17       106\n",
      "        LAW       0.55      0.10      0.17       106\n",
      "        PRN       0.64      0.28      0.39       514\n",
      "        DOC       0.67      0.03      0.06        64\n",
      "        LOC       0.90      0.10      0.17        93\n",
      "      EVENT       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.80      0.82      0.79     12188\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1428: UserWarning: labels size, 11, does not match size of target_names, 12\n",
      "  .format(len(labels), len(target_names))\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "bayes = MultinomialNB().fit(X, Y)\n",
    "predicted = bayes.predict(X)\n",
    "print('accuracy validation set: ', np.mean(predicted == Y))\n",
    "\n",
    "# print scores\n",
    "print(classification_report(Y, predicted, target_names=tag2idx.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
